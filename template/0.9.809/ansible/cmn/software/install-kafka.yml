---
- name: Install Kafka 4.0.0 (KRaft) + AKHQ + MirrorMaker 2 on Ubuntu 24.04
  hosts: all
  become: yes

  ##──────────────────────────────────
  ## Tunables
  ##──────────────────────────────────
  vars:
    # ▸ Versions
    kafka_version: "4.0.0"
    scala_version: "2.13"
    akhq_version: "0.25.1"

    # ▸ Layout
    kafka_install_dir: /opt # parent directory for downloads
    kafka_home: "{{ kafka_install_dir }}/kafka_{{ scala_version }}-{{ kafka_version }}"
    kafka_link: "{{ kafka_install_dir }}/kafka" # constant path via symlink

    kafka_root_dir: /var/lib/kafka # persistent data root
    kafka_data_dir: "{{ kafka_root_dir }}/data"
    kafka_meta_dir: "{{ kafka_root_dir }}/meta"
    kafka_log_dir: /var/log/kafka

    akhq_dir: /opt/akhq
    akhq_port: 5000
    # ▸ Networking (single‑node default)
    kafka_port: 9092
    controller_port: 9093

    kafka_bind_address: 0.0.0.0 # LISTEN on all NICs
    kafka_advertised_address: "{{ ansible_default_ipv4.address }}" # external / VM IP
    kafka_controller_address: "{{ ansible_default_ipv4.address }}" # Raft voters address

    # ▸ Node identity (change for multi‑node)
    kafka_node_id: 1

    # ▸ Resources
    kafka_heap: 4g # adjust to host memory
    mm2_heap: 4g # MirrorMaker 2 (if enabled)
    num_network_threads: 4
    num_io_threads: 8

    # ▸ Optional components
    enable_akhq: true
    enable_mm2: false

    # ▸ Users / groups
    kafka_user: kafka
    kafka_group: kafka

    # ▸ Download URLs
    kafka_tgz: "https://downloads.apache.org/kafka/{{ kafka_version }}/kafka_{{ scala_version }}-{{ kafka_version }}.tgz"
    akhq_jar: "https://github.com/tchiotludo/akhq/releases/download/{{ akhq_version }}/akhq-{{ akhq_version }}-all.jar"

  ##──────────────────────────────────
  ## Tasks
  ##──────────────────────────────────
  tasks:
    - name: Verify Ubuntu 24.04 (noble)
      assert:
        that: ansible_facts['lsb']['codename'] == 'noble'
        fail_msg: "This playbook supports only Ubuntu 24.04 (noble)."

    - name: Install prerequisite packages
      apt:
        name:
          - openjdk-17-jdk
          - wget
          - tar
          - netcat-openbsd
          - ufw
        update_cache: yes

    - name: Ensure kafka user & group
      group:
        name: "{{ kafka_group }}"

    - user:
        name: "{{ kafka_user }}"
        group: "{{ kafka_group }}"
        system: yes
        shell: /usr/sbin/nologin
        createhome: no

    - name: Create directory tree
      file:
        path: "{{ item }}"
        state: directory
        owner: "{{ kafka_user }}"
        group: "{{ kafka_group }}"
        mode: "0755"
      loop:
        - "{{ kafka_root_dir }}"
        - "{{ kafka_data_dir }}"
        - "{{ kafka_meta_dir }}"
        - "{{ kafka_log_dir }}"
        - "{{ akhq_dir }}"
      when: enable_akhq

    #────────────────────── Kafka binaries ──────────────────────
    - name: Download Kafka {{ kafka_version }} if not present
      get_url:
        url: "{{ kafka_tgz }}"
        dest: "/tmp/kafka_{{ scala_version }}-{{ kafka_version }}.tgz"
        mode: "0644"
      register: kafka_download
      until: kafka_download is succeeded
      retries: 3
      delay: 5

    - name: Extract Kafka archive
      unarchive:
        src: "/tmp/kafka_{{ scala_version }}-{{ kafka_version }}.tgz"
        dest: "{{ kafka_install_dir }}"
        remote_src: yes
        creates: "{{ kafka_home }}"

    - name: Symlink kafka → constant path
      file:
        src: "{{ kafka_home }}"
        dest: "{{ kafka_link }}"
        state: link
        force: yes

    - name: Fix ownership recursively
      file:
        path: "{{ kafka_home }}"
        owner: "{{ kafka_user }}"
        group: "{{ kafka_group }}"
        recurse: yes

    #────────────────────── Generate / persist cluster.id ───────
    - name: Check if meta.properties exists
      stat:
        path: "{{ kafka_meta_dir }}/meta.properties"
      register: meta_file

    - name: Read existing cluster.id
      shell: "grep '^cluster.id=' {{ kafka_meta_dir }}/meta.properties | cut -d= -f2"
      register: cluster_id_existing
      when: meta_file.stat.exists
      changed_when: false

    - name: Generate cluster UUID (first run)
      command: "{{ kafka_link }}/bin/kafka-storage.sh random-uuid"
      register: cluster_uuid
      when: not meta_file.stat.exists
      changed_when: false

    - name: Set cluster_id fact
      set_fact:
        cluster_id: "{{ (meta_file.stat.exists | ternary(cluster_id_existing.stdout, cluster_uuid.stdout)).strip() }}"

    #────────────────────── server.properties template ──────────
    - name: Deploy server.properties
      copy:
        dest: "{{ kafka_link }}/config/server.properties"
        owner: "{{ kafka_user }}"
        group: "{{ kafka_group }}"
        mode: "0644"
        content: |
          process.roles=broker,controller
          node.id={{ kafka_node_id }}
          cluster.id={{ cluster_id }}

          controller.listener.names=CONTROLLER
          listeners=PLAINTEXT://{{ kafka_bind_address }}:{{ kafka_port }},CONTROLLER://{{ kafka_bind_address }}:{{ controller_port }}
          advertised.listeners=PLAINTEXT://{{ kafka_advertised_address }}:{{ kafka_port }}
          controller.quorum.voters={{ kafka_node_id }}@{{ kafka_controller_address }}:{{ controller_port }}
          inter.broker.listener.name=PLAINTEXT

          log.dirs={{ kafka_data_dir }}
          metadata.log.dir={{ kafka_meta_dir }}

          num.network.threads={{ num_network_threads }}
          num.io.threads={{ num_io_threads }}
          socket.request.max.bytes=104857600

          offsets.topic.replication.factor=1
          transaction.state.log.replication.factor=1
          transaction.state.log.min.isr=1

          group.initial.rebalance.delay.ms=0
          delete.topic.enable=true
      notify: restart kafka

    #────────────────────── systemd: kafka.service ──────────────
    - name: Install kafka.service
      copy:
        dest: /etc/systemd/system/kafka.service
        owner: root
        group: root
        mode: "0644"
        content: |
          [Unit]
          Description=Apache Kafka (KRaft mode)
          After=network.target

          [Service]
          Type=simple
          User={{ kafka_user }}
          Group={{ kafka_group }}
          Environment="KAFKA_HEAP_OPTS=-Xms{{ kafka_heap }} -Xmx{{ kafka_heap }}"
          Environment="LOG_DIR={{ kafka_log_dir }}"
          ExecStartPre=/usr/bin/bash -c '[[ -f {{ kafka_meta_dir }}/meta.properties ]] || {{ kafka_link }}/bin/kafka-storage.sh format -t {{ cluster_id }} -c {{ kafka_link }}/config/server.properties --ignore-formatted'
          ExecStart={{ kafka_link }}/bin/kafka-server-start.sh {{ kafka_link }}/config/server.properties
          ExecStop={{ kafka_link }}/bin/kafka-server-stop.sh
          Restart=on-failure
          RestartSec=10
          LimitNOFILE=100000

          [Install]
          WantedBy=multi-user.target
      notify: daemon reload

    - systemd:
        name: kafka
        enabled: yes
        state: started
        daemon_reload: yes

    - name: Wait for Kafka to come up
      wait_for:
        host: "{{ kafka_advertised_address }}"
        port: "{{ kafka_port }}"
        timeout: 180
        delay: 5
        state: started

    #────────────────────── UFW rule (optional) ─────────────────
    - name: Allow Kafka port through UFW
      ufw:
        rule: allow
        port: "{{ kafka_port }}"
        proto: tcp

    #────────────────────── AKHQ ────────────────────────────────
    - block:
        - name: Download AKHQ jar
          get_url:
            url: "{{ akhq_jar }}"
            dest: "{{ akhq_dir }}/akhq.jar"
            owner: "{{ kafka_user }}"
            group: "{{ kafka_group }}"
            mode: "0644"
          notify: restart akhq

        - name: AKHQ config
          copy:
            dest: "{{ akhq_dir }}/application.yml"
            owner: "{{ kafka_user }}"
            group: "{{ kafka_group }}"
            mode: "0644"
            content: |
              micronaut:
                server:
                  port: {{ akhq_port }}

              akhq:
                connections:
                  local:
                    properties:
                      bootstrap.servers: "{{ kafka_advertised_address }}:{{ kafka_port }}"
          notify: restart akhq

        - name: AKHQ systemd unit
          copy:
            dest: /etc/systemd/system/akhq.service
            owner: root
            group: root
            mode: "0644"
            content: |
              [Unit]
              Description=AKHQ – Kafka Web UI
              Requires=kafka.service
              After=kafka.service

              [Service]
              Type=simple
              User={{ kafka_user }}
              Group={{ kafka_group }}
              WorkingDirectory={{ akhq_dir }}
              ExecStart=/usr/bin/java -Dmicronaut.config.files={{ akhq_dir }}/application.yml -jar {{ akhq_dir }}/akhq.jar
              Restart=on-failure
              RestartSec=10
              Environment="MICRONAUT_CONFIG_FILES={{ akhq_dir }}/application.yml"
              Environment="MICRONAUT_SERVER_PORT={{ akhq_port }}"

              [Install]
              WantedBy=multi-user.target
          notify:
            - daemon reload
            - restart akhq

        - systemd:
            name: akhq
            enabled: true
            state: started
            daemon_reload: yes

        - name: Apply AKHQ handler changes immediately
          meta: flush_handlers

        - name: Check if AKHQ listens on desired port
          shell: "ss -ltn '( sport = :{{ akhq_port }} )'"
          register: akhq_listen_check
          changed_when: false
          failed_when: false

        - name: Restart AKHQ when port probe fails
          systemd:
            name: akhq
            state: restarted
          when: akhq_listen_check.stdout | trim == ""

        - wait_for:
            host: 127.0.0.1
            port: "{{ akhq_port }}"
            timeout: 120
            delay: 5
            state: started
      when: enable_akhq

    #────────────────────── MirrorMaker2 ─────────────────────────
    - block:
        - name: MM2 config (demo)
          copy:
            dest: "{{ kafka_link }}/config/mm2.properties"
            owner: "{{ kafka_user }}"
            group: "{{ kafka_group }}"
            mode: "0644"
            content: |
              clusters = A, B
              A.bootstrap.servers = {{ kafka_advertised_address }}:{{ kafka_port }}
              B.bootstrap.servers = {{ kafka_advertised_address }}:{{ kafka_port }}
              A->B.enabled = true
              A->B.topics = foo.*
              A->B.emit.heartbeats.enabled = true

        - name: MM2 systemd unit
          copy:
            dest: /etc/systemd/system/mm2.service
            owner: root
            group: root
            mode: "0644"
            content: |
              [Unit]
              Description=Kafka MirrorMaker 2
              Requires=kafka.service
              After=kafka.service

              [Service]
              Type=simple
              User={{ kafka_user }}
              Group={{ kafka_group }}
              Environment="KAFKA_HEAP_OPTS=-Xms{{ mm2_heap }} -Xmx{{ mm2_heap }}"
              WorkingDirectory={{ kafka_link }}
              ExecStart={{ kafka_link }}/bin/connect-mirror-maker.sh {{ kafka_link }}/config/mm2.properties --numStreams 2
              Restart=on-failure
              RestartSec=10

              [Install]
              WantedBy=multi-user.target
          notify: daemon reload

        - systemd:
            name: mm2
            enabled: true
            state: started
            daemon_reload: yes
      when: enable_mm2

  ##──────────────────────────────────
  ## Handlers
  ##──────────────────────────────────
  handlers:
    - name: daemon reload
      systemd:
        daemon_reload: yes

    - name: restart kafka
      systemd:
        name: kafka
        state: restarted

    - name: restart akhq
      systemd:
        name: akhq
        state: restarted
